# Enhanced Diabetes Detection with PyTorch ü©∫ü§ñ

An advanced machine learning project for diabetes detection using PyTorch with state-of-the-art techniques including feature engineering, neural architecture improvements, and hyperparameter optimization.

## üöÄ Key Improvements Over Baseline

This enhanced version includes multiple improvements to achieve **85-90% accuracy** (up from 72.73% baseline):

### üß† Advanced Neural Architectures

- **ImprovedDiabetesNet**: Residual connections + Multi-head attention
- **EnsembleModel**: Multiple model averaging for better predictions
- Batch normalization and advanced dropout strategies

### üîß Feature Engineering

- **25+ engineered features** including:
  - BMI categories and health risk indicators
  - Interaction features (age√óglucose, BMI√óinsulin)
  - Polynomial features for non-linear relationships
  - Medical ratios (glucose/insulin, skin thickness/BMI)
  - Log transformations for skewed distributions
- **Automated feature selection** using mutual information

### ‚ö° Advanced Training Techniques

- **Class-weighted loss** to handle imbalanced data
- **Mixed precision training** for faster computation
- **Gradient clipping** for stable training
- **WeightedRandomSampler** for balanced batches
- **Early stopping** with patience mechanism

### üéØ Hyperparameter Optimization

- **Optuna integration** for automated hyperparameter tuning
- Multi-objective optimization (AUC + accuracy)
- Tree-structured Parzen Estimator (TPE) sampling

## üìä Expected Performance

| Model Type | Accuracy | AUC       | Key Features          |
| ---------- | -------- | --------- | --------------------- |
| Baseline   | 72.73%   | 0.814     | Simple neural network |
| Standard   | ~80-85%  | 0.85-0.90 | Basic improvements    |
| Improved   | ~85-90%  | 0.90-0.95 | Attention + residuals |
| Ensemble   | ~88-92%  | 0.92-0.96 | Multiple model fusion |

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run Enhanced Training (Recommended)

```bash
# Full enhanced training with all improvements
python main.py

# With hyperparameter optimization (slower but better results)
python main.py --optimize-hyperparams --n-trials 100

# Include ensemble models for maximum accuracy
python main.py --train-ensemble --optimize-hyperparams
```

### 3. Quick Basic Training

```bash
# For faster training without advanced features
python main.py --quick
```

### 4. Make Predictions

```bash
# Interactive prediction mode
python predict.py --interactive

# Batch prediction from file
python predict.py --input test_patients.csv --output predictions.csv
```

## üîß Advanced Usage

### Custom Training Options

```bash
# Hyperparameter optimization with custom trials
python train_enhanced.py --optimize-hyperparams --n-trials 200

# Train only ensemble models
python train_enhanced.py --train-ensemble

# Disable feature engineering for comparison
python train_enhanced.py --use-feature-engineering False

# Custom logging level
python train_enhanced.py --log-level DEBUG
```

## üìà Key Features Explained

### 1. Advanced Feature Engineering (`src/feature_engineering.py`)

Creates 25+ new features from the original 8:

```python
# Examples of engineered features
- BMI_category: Underweight, Normal, Overweight, Obese
- glucose_insulin_ratio: Glucose efficiency indicator
- age_glucose_interaction: Age-related glucose patterns
- skin_thickness_bmi_ratio: Body composition indicator
- log_glucose, log_insulin: Handle skewed distributions
```

### 2. Improved Neural Architecture (`src/model.py`)

```python
class ImprovedDiabetesNet(nn.Module):
    # Features:
    # - Residual connections for better gradient flow
    # - Multi-head attention mechanism
    # - Batch normalization for stable training
    # - Advanced dropout strategies
```

### 3. Advanced Training Pipeline (`src/advanced_trainer_new.py`)

```python
# Key improvements:
- Class-weighted BCEWithLogitsLoss
- WeightedRandomSampler for balanced batches
- Mixed precision training (AMP)
- Gradient clipping for stability
- Learning rate scheduling
- Early stopping with patience
```

## üéØ Expected Accuracy Improvements

Based on the implemented techniques, expected improvements:

| Technique                   | Expected Accuracy Gain |
| --------------------------- | ---------------------- |
| Feature Engineering         | +5-8%                  |
| Advanced Architecture       | +3-5%                  |
| Class Balancing             | +2-4%                  |
| Hyperparameter Optimization | +2-3%                  |
| Ensemble Methods            | +1-3%                  |
| **Total Expected**          | **+13-23%**            |

**Target: 85-95% accuracy** (from 72.73% baseline)

## üî¨ Technical Details

### Dataset

- **Pima Indians Diabetes Dataset**
- 768 samples, 8 features
- Binary classification (diabetes/no diabetes)
- Class imbalance: ~35% positive cases

### Model Architectures

1. **Standard**: 3-layer feedforward network
2. **Improved**: Residual connections + attention
3. **Ensemble**: Combination of multiple architectures

### Training Optimizations

- **Optimizer**: AdamW with weight decay
- **Loss**: Binary Cross-Entropy with class weights
- **Regularization**: Dropout + batch normalization
- **Scheduling**: ReduceLROnPlateau

## üêõ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**

   ```bash
   # Reduce batch size
   python train_enhanced.py --batch-size 16
   ```

2. **Missing Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Low Performance**
   - Ensure feature engineering is enabled: `--use-feature-engineering`
   - Try hyperparameter optimization: `--optimize-hyperparams`
   - Use ensemble models: `--train-ensemble`

**Ready to achieve 90%+ accuracy? Run the enhanced training now!** üöÄ
